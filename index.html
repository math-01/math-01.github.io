<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>OCR Mobile Avançado</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      font-family: Arial, sans-serif;
      background: #111;
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      height: 100vh;
    }
    #container {
      width: 100%;
      max-width: 480px;
      padding: 12px;
      display: flex;
      flex-direction: column;
      gap: 12px;
    }
    video {
      width: 100%;
      border-radius: 12px;
      background: black;
    }
    canvas {
      display: none;
    }
    #output {
      background: #222;
      padding: 12px;
      border-radius: 10px;
      font-size: 16px;
      min-height: 80px;
      white-space: pre-wrap;
    }
    #status {
      font-size: 14px;
      opacity: 0.7;
    }
    button {
      width: 100%;
      padding: 14px;
      border: none;
      border-radius: 10px;
      background: #00aaff;
      color: white;
      font-size: 18px;
    }
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>

    <button id="toggle">Pausar OCR</button>
    <div id="status">Iniciando...</div>
    <div id="output"></div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>

  <script>
    let running = true;
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const output = document.getElementById("output");
    const statusEl = document.getElementById("status");

    document.getElementById("toggle").onclick = () => {
      running = !running;
      document.getElementById("toggle").innerText = running ? "Pausar OCR" : "Retomar OCR";
    };

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "environment",
          width: { ideal: 720 },
          height: { ideal: 480 }
        }
      });
      video.srcObject = stream;
    }

    function detectROI(grayMat) {
      let edges = new cv.Mat();
      cv.Canny(grayMat, edges, 60, 120);
      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      let bestRect = null;
      for (let i = 0; i < contours.size(); i++) {
        let cnt = contours.get(i);
        let rect = cv.boundingRect(cnt);
        if (rect.width > grayMat.cols * 0.3 && rect.height > 40) {
          bestRect = rect;
        }
      }
      edges.delete(); contours.delete(); hierarchy.delete();
      return bestRect;
    }

    function preprocess(src) {
      let gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      let roiRect = detectROI(gray) || {x:0, y:0, width:gray.cols, height:gray.rows};
      let roi = gray.roi(roiRect);

      let blur = new cv.Mat();
      cv.GaussianBlur(roi, blur, new cv.Size(3,3), 0);
      let th = new cv.Mat();
      cv.adaptiveThreshold(blur, th, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 35, 8);

      let kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(2,2));
      let closed = new cv.Mat();
      cv.morphologyEx(th, closed, cv.MORPH_CLOSE, kernel);

      gray.delete(); blur.delete(); th.delete(); kernel.delete();
      return closed;
    }

    async function processFrame(worker) {
      if (!running) return requestAnimationFrame(() => processFrame(worker));
      if (video.readyState !== 4) return requestAnimationFrame(() => processFrame(worker));

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);

      let src = cv.imread(canvas);
      let processed = preprocess(src);

      const data = new Uint8ClampedArray(processed.data);
      const imgData = new ImageData(data, processed.cols, processed.rows);
      ctx.putImageData(imgData, 0, 0);

      const blob = await new Promise(res => canvas.toBlob(res, "image/png"));
      worker.recognize(blob).then(({data}) => {
        output.innerText = data.text.trim();
        statusEl.innerText = "Confiança: " + Math.round(data.confidence) + "%";
      });

      src.delete(); processed.delete();
      requestAnimationFrame(() => processFrame(worker));
    }

    async function onOpenCvReady() {
      statusEl.innerText = "Carregando OCR avançado...";
      const worker = await Tesseract.createWorker("por", 1, {
        logger: m => statusEl.innerText = m.status || "Processando..."
      });

      await startCamera();
      requestAnimationFrame(() => processFrame(worker));
    }
  </script>
</body>
</html>
